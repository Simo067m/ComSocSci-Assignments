{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(movie_data_path, genre_data_path):\n",
    "    \"\"\"\n",
    "    Loads the JSON data from the given file paths and returns the JSON objects.\n",
    "    \"\"\"\n",
    "    movie_data_path = 'final_movie_data.json'\n",
    "    genre_data_path = \"movie_genres.json\"\n",
    "    movie_json_objects = []\n",
    "    genre_json_objects = []\n",
    "\n",
    "    with open(movie_data_path, 'r') as file:\n",
    "        for line in tqdm(file, desc='Reading JSON'):\n",
    "            json_object = json.loads(line)\n",
    "            movie_json_objects.append(json_object)\n",
    "\n",
    "    with open(genre_data_path, 'r') as file:\n",
    "        for line in file:\n",
    "            json_object = json.loads(line)\n",
    "            genre_json_objects.append(json_object)\n",
    "    \n",
    "    return movie_json_objects, genre_json_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_dataframe(movie_json_objects, genre_json_objects):\n",
    "    \"\"\"\n",
    "    Converts the JSON objects to pandas dataframes and sets the genre_id as the index for the genres dataframe.\n",
    "    Also removes movies with no genres and movies with multiple genres.\n",
    "    \"\"\"\n",
    "    movies_df = pd.json_normalize(movie_json_objects)\n",
    "    genres_df = pd.json_normalize(genre_json_objects)\n",
    "\n",
    "    genres_df.set_index(\"genre_id\", inplace=True)\n",
    "    empty_genres = movies_df[movies_df['combined_genres'].apply(lambda x: len(x) == 0)]\n",
    "    multiple_genres = movies_df[movies_df['combined_genres'].apply(lambda x: len(x) > 1)]\n",
    "    movies_df = movies_df.drop(empty_genres.index)\n",
    "    movies_df = movies_df.drop(multiple_genres.index)\n",
    "    movies_df = movies_df.reset_index(drop=True)\n",
    "\n",
    "    return movies_df, genres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(movies_df, genres_df):\n",
    "    \"\"\"\n",
    "    Adds the genre names to the movies dataframe by loading the genre names from the genres dataframe.\n",
    "    \"\"\"\n",
    "    movies_df[\"genre\"] = genres_df.loc[movies_df[\"combined_genres\"].apply(lambda x: x[0]), \"genre_name\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_by_genre(movies_df):\n",
    "    \"\"\"\n",
    "    Seperates the movies dataframe into multiple dataframes based on the genre.\n",
    "    \"\"\"\n",
    "    genre_dfs = {}\n",
    "    for genre in movies_df[\"genre\"].unique():\n",
    "        genre_dfs[genre] = movies_df[movies_df[\"genre\"] == genre]\n",
    "    return genre_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_overviews(genre_dfs):\n",
    "    combined_overviews = {}\n",
    "\n",
    "    for genre, df in genre_dfs.items():\n",
    "        overviews = df[\"overview\"].tolist()\n",
    "        combined_overview = \" \".join(overviews)\n",
    "        combined_overviews[genre] = combined_overview\n",
    "    \n",
    "    return combined_overviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for tokeniizing\n",
    "\n",
    "def stem(word):\n",
    "     regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "     stem, suffix = re.findall(regexp, word)[0]\n",
    "     return stem\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Exlcude punctuation, urls, symbols and numbers using isalpha() method\n",
    "    tokens = [stemmer.stem(token.lower()) for token in tokens if token.isalpha()]\n",
    "    #tokens = sorted(set(tokens))\n",
    "\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for TF-IDF\n",
    "\n",
    "def term_frequency(tokens : list):\n",
    "    # Find the frequency of each token\n",
    "    frequency = nltk.FreqDist(tokens)\n",
    "    # Find the total number of tokens\n",
    "    total_tokens = len(tokens)\n",
    "    # Find the frequency of each token\n",
    "    term_frequency = {token : frequency[token] / total_tokens for token in frequency}\n",
    "    return term_frequency\n",
    "\n",
    "def inverse_document_frequency(genre_tokens : dict):\n",
    "    documents = genre_tokens.values()\n",
    "    # Find the number of documents\n",
    "    number_of_documents = len(documents)\n",
    "    # Find the number of documents containing each token\n",
    "    document_frequency = {}\n",
    "    for document in documents:\n",
    "        for token in set(document):\n",
    "            if token not in document_frequency:\n",
    "                document_frequency[token] = 1\n",
    "            else:\n",
    "                document_frequency[token] += 1\n",
    "    # Find the inverse document frequency of each token\n",
    "    inverse_document_frequency = {token : np.log10(number_of_documents / document_frequency[token]) for token in document_frequency}\n",
    "    return inverse_document_frequency\n",
    "\n",
    "def tf_idf(term_frequency : dict, inverse_document_frequency : dict):\n",
    "    # Find the TF-IDF score of each token\n",
    "    tf_idf = {token : term_frequency[token] * inverse_document_frequency[token] for token in term_frequency}\n",
    "    return tf_idf\n",
    "\n",
    "def get_genre_tf_idf(genre_tokens : dict):\n",
    "    # Find the term frequency of each token in each genre\n",
    "    genre_term_frequencies = {genre : term_frequency(tokens) for genre, tokens in genre_tokens.items()}\n",
    "    # Find the inverse document frequency of each token in each genre\n",
    "    genre_inverse_document_frequencies = inverse_document_frequency(genre_tokens)\n",
    "    # Find the TF-IDF score of each token in each genre\n",
    "    genre_tf_idf = {genre : tf_idf(genre_term_frequencies[genre], genre_inverse_document_frequencies) for genre in genre_tokens}\n",
    "    return genre_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for creating a word cloud\n",
    "def create_word_cloud(tokens : list):\n",
    "    # Find the frequency of each token\n",
    "    frequency = nltk.FreqDist(tokens)\n",
    "    # Create a word cloud\n",
    "    cloud = wordcloud.WordCloud(width = 800, height = 400, background_color = \"white\").generate_from_frequencies(frequency)\n",
    "    return cloud\n",
    "\n",
    "# Define a function for plotting the word cloud\n",
    "def plot_word_cloud(cloud : wordcloud.WordCloud, genre):\n",
    "    plt.figure(figsize = (6, 3))\n",
    "    plt.imshow(cloud, interpolation = \"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Genre: {genre}\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_genre_clouds(genre_tokens : dict):\n",
    "    for genre, overview in genre_tokens.items():\n",
    "        word_cloud = create_word_cloud(overview)\n",
    "        plot_word_cloud(word_cloud, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading JSON: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading JSON: 199897it [00:09, 20758.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the json data\n",
    "movie_json_objects, genre_json_objects = load_json_data(\"final_movie_data.json\", \"movie_genres.json\")\n",
    "\n",
    "# Create and format dataframes from the data\n",
    "movies_df, genres_df = json_to_dataframe(movie_json_objects, genre_json_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the genre names to the movies dataframe\n",
    "get_genres(movies_df, genres_df)\n",
    "\n",
    "# Seperate the movies dataframe into multiple dataframes based on the genre\n",
    "genre_dfs = seperate_by_genre(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Comedy': 8751, 'Drama': 14391, 'Thriller': 1688, 'Documentary': 35737, 'Music': 6057, 'Animation': 5580, 'Horror': 6508, 'Western': 174, 'Fantasy': 404, 'Action': 971, 'TV Movie': 101, 'History': 173, 'Science Fiction': 1178, 'Mystery': 265, 'Family': 510, 'Romance': 660, 'Crime': 335, 'Adventure': 177, 'War': 65}\n"
     ]
    }
   ],
   "source": [
    "# Print the number of movies under each genre\n",
    "lengths = {genre: len(df) for genre, df in genre_dfs.items()}\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the overviews of the movies in each genre\n",
    "combined_overviews = combine_overviews(genre_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 19/19 [01:07<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "genre_tokens = {genre: tokenize_text(overview) for genre, overview in tqdm(combined_overviews.items(), desc='Tokenizing')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_tf_idfs = get_genre_tf_idf(genre_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_genre_clouds(genre_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
